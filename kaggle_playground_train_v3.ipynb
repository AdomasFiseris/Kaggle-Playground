{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06932f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.compose         import ColumnTransformer\n",
    "from sklearn.preprocessing   import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics         import make_scorer\n",
    "from sklearn.base            import clone\n",
    "from xgboost                 import XGBRegressor\n",
    "import joblib, mlflow\n",
    "import mlflow.sklearn\n",
    "import optuna\n",
    "import warnings\n",
    "from optuna.integration import OptunaSearchCV, MLflowCallback\n",
    "from optuna.distributions import FloatDistribution, IntDistribution\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "# Custom Metric for Training Feedback\n",
    "def rmsle_xgb(preds, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    preds = np.maximum(preds, 0)\n",
    "    rmsle = np.sqrt(np.mean((np.log1p(preds) - np.log1p(y_true)) ** 2))\n",
    "    return 'rmsle', rmsle\n",
    "\n",
    "# Custom Metric for GridSearch (wrapped in make_scorer)\n",
    "def rmsle_sklearn(y_true, y_pred):\n",
    "    y_pred = np.maximum(y_pred, 0)\n",
    "    return np.sqrt(np.mean((np.log1p(y_pred) - np.log1p(y_true)) ** 2))\n",
    "\n",
    "rmsle_scorer = make_scorer(rmsle_sklearn, greater_is_better=False)\n",
    "# Data\n",
    "df = pd.read_csv('playground-series-s5e5/train.csv')\n",
    "y = df['Calories']\n",
    "X = df.drop(columns=(['Calories', 'id']))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=X['Sex']\n",
    ")\n",
    "\n",
    "# Custom Feature Engineering\n",
    "def add_bmi_intensity(X_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Adds BMI and HeartRatexDuration features\"\"\"\n",
    "    X = X_df.copy()\n",
    "    X['BMI'] = (X['Weight'] / (X['Height'] / 100) ** 2).round(2)\n",
    "    X['Timed_Intensity'] = X['Duration'] * X['Heart_Rate']\n",
    "    return X\n",
    "\n",
    "feat_eng = FunctionTransformer(add_bmi_intensity, validate=False)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MODEL & PIPELINE\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cat_model = CatBoostRegressor(\n",
    "        loss_function=\"RMSE\",\n",
    "        random_seed=42,\n",
    "        verbose=False,\n",
    "        cat_features=[\"Sex\"]\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"feat_eng\", feat_eng),\n",
    "    (\"model\", cat_model)\n",
    "])\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# GRID  (prefix params with model__)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def cat_objective(trial):\n",
    "    params = {\n",
    "        \"model__depth\":               trial.suggest_int(\"model__depth\", 5, 10),\n",
    "        \"model__iterations\":          trial.suggest_int(\"model__iterations\", 600, 1600),\n",
    "        \"model__learning_rate\":       trial.suggest_float(\"model__learning_rate\", 0.01, 0.2, log=True),\n",
    "        \"model__l2_leaf_reg\":         trial.suggest_float(\"model__l2_leaf_reg\", 1, 10, log=True),\n",
    "        \"model__bagging_temperature\": trial.suggest_float(\"model__bagging_temperature\", 0, 1),\n",
    "    }\n",
    "\n",
    "    score = cross_val_score(\n",
    "                clone(pipe).set_params(**params),\n",
    "                X_train, y_train,\n",
    "                scoring=rmsle_scorer,\n",
    "                cv=5,\n",
    "                n_jobs=-1\n",
    "            ).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f17d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# MLFLOW + OPTUNA LOOP  (same structure)\n",
    "# ------------------------------------------------------------------\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "\n",
    "mlflow.set_experiment(\"Calories-CB-Optuna-V1\")\n",
    "mlflow.sklearn.autolog(log_models=False)\n",
    "\n",
    "'''\n",
    "study_cb = optuna.create_study(direction=\"maximize\", study_name=\"cat_rmsle_1\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"optuna_parent_cb\"):\n",
    "    mlflow_cb = MLflowCallback(\n",
    "        tracking_uri=mlflow.get_tracking_uri(),\n",
    "        metric_name=\"neg_rmsle_cv\",\n",
    "        mlflow_kwargs={\"nested\": True}\n",
    "    )\n",
    "\n",
    "    study_cb.optimize(cat_objective, n_trials=50, callbacks=[mlflow_cb], show_progress_bar=True)\n",
    "\n",
    "    mlflow.log_params(study_cb.best_trial.params)\n",
    "    mlflow.log_metric(\"best_neg_rmsle_cv\", study_cb.best_value)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e0cfe2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 20:09:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/20 20:09:12 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run catboost_final_fit at: http://127.0.0.1:5000/#/experiments/0/runs/5c2f1f373f894ce196135439dcd90c56.\n",
      "2025/05/20 20:09:12 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/0.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Best hyper-parameters returned by Optuna\n",
    "# ------------------------------------------------------------------\n",
    "best_params = {\n",
    "    \"model__depth\":               10,\n",
    "    \"model__iterations\":          1395,\n",
    "    \"model__learning_rate\":       0.0714922129952202,\n",
    "    \"model__l2_leaf_reg\":         1.66331352625327,\n",
    "    \"model__bagging_temperature\": 0.5336964163281406,\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Rebuild the final pipeline\n",
    "# (reuse the same feat_eng transformer defined earlier)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "cat_final = CatBoostRegressor(\n",
    "        loss_function=\"RMSE\",\n",
    "        random_seed=42,\n",
    "        verbose=False,\n",
    "        cat_features=[\"Sex\"]\n",
    ")\n",
    "\n",
    "final_pipe = Pipeline([\n",
    "        (\"feat_eng\", feat_eng),\n",
    "        (\"model\",    cat_final)\n",
    "]).set_params(**best_params)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Fit on the full dataset (train + val)\n",
    "# ------------------------------------------------------------------\n",
    "X_full = pd.concat([X_train, X_val])\n",
    "y_full = pd.concat([y_train, y_val])\n",
    "\n",
    "final_pipe.fit(X_full, y_full)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Save / log the artefact\n",
    "# ------------------------------------------------------------------\n",
    "joblib.dump(final_pipe, \"calories_catboost_optuna.joblib\")\n",
    "\n",
    "# Log to MLflow\n",
    "with mlflow.start_run(run_name=\"catboost_final_fit\"):\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.sklearn.log_model(final_pipe, artifact_path=\"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74799dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run found: 4d6d9579b71d4906ac6c0a111e83f79f\n"
     ]
    }
   ],
   "source": [
    "# LOADING XGBOOST FINAL FROM MLFLOW  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "exp = mlflow.get_experiment_by_name(\"Calories-XGB-Optuna-V1\")\n",
    "\n",
    "runs = mlflow.search_runs(\n",
    "        experiment_ids=[exp.experiment_id],\n",
    "        filter_string='tags.mlflow.runName = \"final_rmsle_model_optuna\"',\n",
    "        order_by=[\"start_time DESC\"],\n",
    "        max_results=1,\n",
    ")\n",
    "final_run_id = runs.iloc[0].run_id\n",
    "print(\"Run found:\", final_run_id)\n",
    "xgb_final = mlflow.sklearn.load_model(f\"runs:/{final_run_id}/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Custom Metric for Training Feedback\n",
    "def rmsle_xgb(preds, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    preds = np.maximum(preds, 0)\n",
    "    rmsle = np.sqrt(np.mean((np.log1p(preds) - np.log1p(y_true)) ** 2))\n",
    "    return 'rmsle', rmsle\n",
    "\n",
    "# Custom Metric for GridSearch (wrapped in make_scorer)\n",
    "def rmsle_sklearn(y_true, y_pred):\n",
    "    y_pred = np.maximum(y_pred, 0)\n",
    "    return np.sqrt(np.mean((np.log1p(y_pred) - np.log1p(y_true)) ** 2))\n",
    "\n",
    "rmsle_scorer = make_scorer(rmsle_sklearn, greater_is_better=False)\n",
    "\n",
    "# Data\n",
    "df = pd.read_csv('playground-series-s5e5/train.csv')\n",
    "y = df['Calories']\n",
    "X = df.drop(columns=(['Calories', 'id']))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=X['Sex']\n",
    ")\n",
    "\n",
    "# Custom Feature Engineering\n",
    "def add_bmi_intensity(X_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Adds BMI and HeartRatexDuration features\"\"\"\n",
    "    X = X_df.copy()\n",
    "    X['BMI'] = (X['Weight'] / (X['Height'] / 100) ** 2).round(2)\n",
    "    X['Timed_Intensity'] = X['Duration'] * X['Heart_Rate']\n",
    "    return X\n",
    "\n",
    "feat_eng = FunctionTransformer(add_bmi_intensity, validate=False)\n",
    "\n",
    "# Preprocessor\n",
    "cat_col = ['Sex']\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first'), cat_col)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MODEL & PIPELINE\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "xgb = XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=42,\n",
    "        n_estimators=800,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8\n",
    ")\n",
    "\n",
    "xgb_pipe = Pipeline(steps=[\n",
    "        (\"feat_eng\",   feat_eng),\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"model\",      xgb)\n",
    "])\n",
    "\n",
    "best_params = {\n",
    "    \"model__max_depth\": 9,\n",
    "    \"model__learning_rate\": 0.023658702935574594,\n",
    "    \"model__n_estimators\": 1373,\n",
    "    \"model__subsample\": 0.9815205434675509,\n",
    "    \"model__colsample_bytree\": 0.8460760959011027,\n",
    "    \"model__reg_alpha\": 0.4849891315002537,\n",
    "    \"model__reg_lambda\": 1.6645566204520426,\n",
    "    \"model__min_child_weight\": 0.37163348840668015\n",
    "    }\n",
    "\n",
    "# fresh clone to avoid any state leakage from grid-search\n",
    "best_xgb_pipe = clone(xgb_pipe).set_params(\n",
    "        **best_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96ffdd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# OPTIMIZING WEIGHT\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "best_xgb_pipe.fit(X_train, y_train)\n",
    "final_pipe.fit(X_train, y_train)\n",
    "\n",
    "xgb_val = best_xgb_pipe.predict(X_val)\n",
    "cat_val = final_pipe.predict(X_val)\n",
    "\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "def blend_rmsle(w):\n",
    "    blended = w * xgb_val + (1 - w) * cat_val\n",
    "    return rmsle_sklearn(y_val, blended)\n",
    "\n",
    "w_opt = minimize_scalar(blend_rmsle, bounds=(0, 1), method=\"bounded\").x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce896c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# TEST SET RUN\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "df_test_cat = pd.read_csv(\"playground-series-s5e5/test.csv\")\n",
    "ids_cat = df_test_cat[\"id\"]\n",
    "\n",
    "X_test_cat = df_test_cat.drop(columns=[\"id\"])\n",
    "test_preds_cat = final_pipe.predict(X_test_cat)\n",
    "\n",
    "df_test_xgb = pd.read_csv(\"playground-series-s5e5/test.csv\")\n",
    "ids_xgb = df_test_xgb[\"id\"]\n",
    "\n",
    "X_test_xgb = df_test_xgb.drop(columns=[\"id\"])\n",
    "test_preds_xgb = best_xgb_pipe.predict(X_test_xgb)\n",
    "\n",
    "final_pred = w_opt * test_preds_xgb + (1 - w_opt) * test_preds_cat\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": ids_cat,\n",
    "    \"Calories\": final_pred\n",
    "})\n",
    "\n",
    "import os\n",
    "if os.path.isfile(\"submission_3.csv\"):\n",
    "    pass\n",
    "else:\n",
    "    submission.to_csv(\"submission_3.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
