{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06932f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.preprocessing   import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics         import make_scorer\n",
    "from sklearn.base            import clone\n",
    "import joblib, mlflow\n",
    "import mlflow.sklearn\n",
    "import optuna\n",
    "from optuna.integration import MLflowCallback\n",
    "from catboost import CatBoostRegressor\n",
    "from pathlib import Path\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import ttest_rel\n",
    "from scipy.optimize import minimize_scalar, minimize\n",
    "\n",
    "# Custom Metric for Training Feedback\n",
    "def rmsle_xgb(preds, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    preds = np.maximum(preds, 0)\n",
    "    rmsle = np.sqrt(np.mean((np.log1p(preds) - np.log1p(y_true)) ** 2))\n",
    "    return 'rmsle', rmsle\n",
    "\n",
    "# Custom Metric for GridSearch (wrapped in make_scorer)\n",
    "def rmsle_sklearn(y_true, y_pred):\n",
    "    y_pred = np.maximum(y_pred, 0)\n",
    "    return np.sqrt(np.mean((np.log1p(y_pred) - np.log1p(y_true)) ** 2))\n",
    "\n",
    "rmsle_scorer = make_scorer(rmsle_sklearn, greater_is_better=False)\n",
    "\n",
    "# Data\n",
    "df = pd.read_csv('playground-series-s5e5/train.csv')\n",
    "y = df['Calories']\n",
    "X = df.drop(columns=(['Calories', 'id']))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=X['Sex']\n",
    ")\n",
    "\n",
    "# Custom Feature Engineering\n",
    "def add_bmi_intensity(X_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Adds BMI and HeartRatexDuration features\"\"\"\n",
    "    X = X_df.copy()\n",
    "    X['BMI'] = (X['Weight'] / (X['Height'] / 100) ** 2).round(2)\n",
    "    X['Timed_Intensity'] = X['Duration'] * X['Heart_Rate']\n",
    "    X['Heart_Rate_Zone'] = (\n",
    "        X['Heart_Rate'] / (220 - X['Age'])\n",
    "    ) * 100\n",
    "    X['Mifflin_Jeor_BMR'] = np.where(\n",
    "        X['Sex'] == 'male',\n",
    "        (10 * X['Weight']) + (6.25 * X['Height']) - (5 * X['Age']) + 5,\n",
    "        (10 * X['Weight']) + (6.25 * X['Height']) - (5 * X['Age']) - 161,\n",
    "    )\n",
    "    return X\n",
    "\n",
    "feat_eng = FunctionTransformer(add_bmi_intensity, validate=False)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# MODEL & PIPELINE\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "cat_model = CatBoostRegressor(\n",
    "        loss_function=\"RMSE\",\n",
    "        random_seed=42,\n",
    "        verbose=False,\n",
    "        cat_features=[\"Sex\"]\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"feat_eng\", feat_eng),\n",
    "    (\"model\", cat_model)\n",
    "])\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# GRID  (prefix params with model__)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "def cat_objective(trial):\n",
    "    params = {\n",
    "        \"model__depth\":               trial.suggest_int(\"model__depth\", 5, 10),\n",
    "        \"model__iterations\":          trial.suggest_int(\"model__iterations\", 600, 1600),\n",
    "        \"model__learning_rate\":       trial.suggest_float(\"model__learning_rate\", 0.01, 0.2, log=True),\n",
    "        \"model__l2_leaf_reg\":         trial.suggest_float(\"model__l2_leaf_reg\", 1, 10, log=True),\n",
    "        \"model__bagging_temperature\": trial.suggest_float(\"model__bagging_temperature\", 0, 1),\n",
    "    }\n",
    "\n",
    "    score = cross_val_score(\n",
    "                clone(pipe).set_params(**params),\n",
    "                X_train, y_train,\n",
    "                scoring=rmsle_scorer,\n",
    "                cv=5,\n",
    "                n_jobs=-1\n",
    "            ).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0587525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------------\n",
    "# MLFLOW + OPTUNA LOOP  (same structure)\n",
    "# ------------------------------------------------------------------\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"Calories-CB-Optuna-V3\")\n",
    "mlflow.sklearn.autolog(log_models=False)\n",
    "\n",
    "study_cb = optuna.create_study(direction=\"maximize\", study_name=\"cat_rmsle_1\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"optuna_parent_cb\"):\n",
    "    mlflow_cb = MLflowCallback(\n",
    "        tracking_uri=mlflow.get_tracking_uri(),\n",
    "        metric_name=\"neg_rmsle_cv\",\n",
    "        mlflow_kwargs={\"nested\": True}\n",
    "    )\n",
    "\n",
    "    study_cb.optimize(cat_objective, n_trials=50, callbacks=[mlflow_cb], show_progress_bar=True)\n",
    "\n",
    "    mlflow.log_params(study_cb.best_trial.params)\n",
    "    mlflow.log_metric(\"best_neg_rmsle_cv\", study_cb.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de411de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>rmsle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.060914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.060836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.060249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.061157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.060671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold     rmsle\n",
       "0     1  0.060914\n",
       "1     2  0.060836\n",
       "2     3  0.060249\n",
       "3     4  0.061157\n",
       "4     5  0.060671"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/31 12:52:04 INFO mlflow.tracking._tracking_service.client: 🏃 View run cb_oof_fit at: http://127.0.0.1:5000/#/experiments/28/runs/6f5d9125b174428c8c819ec3f43388b4.\n",
      "2025/05/31 12:52:04 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold CV RMSLE: 0.06077\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# GENERATING OOF PREDICTIONS AND A VAL SCORE\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "FE_VERSION = 'v4_hrzone_bmr_cb'\n",
    "\n",
    "best_params = {\n",
    "    \"model__depth\":               10,\n",
    "    \"model__iterations\":          1594,\n",
    "    \"model__learning_rate\":       0.08318728723922084,\n",
    "    \"model__l2_leaf_reg\":         3.7912206788501206,\n",
    "    \"model__bagging_temperature\": 0.3000645110427449,\n",
    "}\n",
    "\n",
    "cat_pipe = clone(pipe).set_params(**best_params)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_table = []\n",
    "oof_cb = np.empty(len(X))\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"Calories-CB-OOF-FINAL\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"cb_oof_fit\",\n",
    "                      tags={\"fe_version\": FE_VERSION}):\n",
    "    \n",
    "    for fold, (tr_idx, val_idx) in enumerate(tqdm(kf.split(X, y), total=kf.get_n_splits()), 1):\n",
    "        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "\n",
    "        fold_model = clone(cat_pipe).fit(X_tr, y_tr)\n",
    "        preds = fold_model.predict(X_val)\n",
    "\n",
    "        oof_cb[val_idx] = preds\n",
    "\n",
    "        fold_rmsle = rmsle_sklearn(y_val, preds)\n",
    "        mlflow.log_metric(f\"fold{fold}_rmsle\", fold_rmsle)\n",
    "\n",
    "        fold_table.append({\"fold\": fold, \"rmsle\": fold_rmsle})\n",
    "        clear_output(wait=True)\n",
    "        display(pd.DataFrame(fold_table))\n",
    "\n",
    "    cv_rmsle = np.mean([row[\"rmsle\"] for row in fold_table])\n",
    "    mlflow.log_metric(\"cv_rmsle\", cv_rmsle)\n",
    "    print(f\"5-fold CV RMSLE: {cv_rmsle:.5f}\")\n",
    "\n",
    "    Path(\"oof\").mkdir(exist_ok=True)\n",
    "    np.save(\"oof/oof_cb.npy\", oof_cb)\n",
    "    mlflow.log_artifact(\"oof/oof_cb.npy\", artifact_path=\"oof\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3771f95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c3fc1c511948769919b2a454e2b81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf684e075834b44a0778e2c8ccab273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c644de6696d4d0b948ca0806d0a9f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shapes  → XGB: (750000,) CB : (750000,) NN : (750000,)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# helper: download a single artefact from MLflow into a temp folder\n",
    "# ------------------------------------------------------------------\n",
    "def load_np(run_id: str, artifact_path: str) -> np.ndarray:\n",
    "    local_path = mlflow.artifacts.download_artifacts(\n",
    "        run_id=run_id,\n",
    "        artifact_path=artifact_path\n",
    "    )\n",
    "    return np.load(local_path)\n",
    "\n",
    "def get_experiment_or_die(name: str):\n",
    "    exp = mlflow.get_experiment_by_name(name)\n",
    "    if exp is None:\n",
    "        raise ValueError(f\"No experiment called '{name}' in current tracking store.\")\n",
    "    return exp\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# locate the runs that hold the OOF .npy files\n",
    "# ------------------------------------------------------------------\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "exp_xgb = get_experiment_or_die(\"Calories-XGB-OOF-FINAL-GOLDEN\")\n",
    "exp_cb  = get_experiment_or_die(\"Calories-CB-OOF-FINAL\")\n",
    "exp_nn  = get_experiment_or_die(\"Calories-NN-OOF-VAL-V2\")      # NEW\n",
    "\n",
    "run_xgb = client.search_runs(exp_xgb.experiment_id,\n",
    "                             \"tags.mlflow.runName = 'xgb_oof_fit'\")[0]\n",
    "run_cb  = client.search_runs(exp_cb.experiment_id,\n",
    "                             \"tags.mlflow.runName = 'cb_oof_fit'\")[0]\n",
    "run_nn  = client.search_runs(exp_nn.experiment_id,             # NEW\n",
    "                             \"tags.mlflow.runName = 'nn_oof_fit'\")[0]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# download & load\n",
    "# ------------------------------------------------------------------\n",
    "oof_xgb = load_np(run_xgb.info.run_id, \"oof/oof_xgb.npy\")\n",
    "oof_cb  = load_np(run_cb.info.run_id,  \"oof/oof_cb.npy\")\n",
    "oof_nn  = load_np(run_nn.info.run_id,  \"oof/oof_nn.npy\")       # NEW\n",
    "\n",
    "print(\"Loaded shapes  →\",\n",
    "      \"XGB:\", oof_xgb.shape,\n",
    "      \"CB :\", oof_cb.shape,\n",
    "      \"NN :\", oof_nn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37de44cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_ridge.py:2341: FutureWarning: 'store_cv_values' is deprecated in version 1.5 and will be removed in 1.7. Use 'store_cv_results' instead.\n",
      "  warnings.warn(\n",
      "2025/05/31 17:28:07 INFO mlflow.tracking._tracking_service.client: 🏃 View run ridge_meta at: http://127.0.0.1:5000/#/experiments/31/runs/b24e8402eff04dcea20399e493aae388.\n",
      "2025/05/31 17:28:07 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/31.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved stacked ridge ✅  –  OOF RMSLE: 0.059810\n"
     ]
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────────\n",
    "#  STACKING  ➜  meta-learner on top of the three base OOF predictions\n",
    "# ────────────────────────────────────────────────────────────────────\n",
    "import numpy as np, pandas as pd, joblib, mlflow\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 0.  Prepare meta-features  (make sure oof_xgb / oof_cb / oof_nn exist)\n",
    "# -------------------------------------------------------------------\n",
    "X_meta = np.vstack([oof_xgb, oof_cb, oof_nn]).T         # shape (n_samples, 3)\n",
    "y_meta = y_true                                         # ground-truth targets\n",
    "\n",
    "# 1-line RMSLE scorer (same as before)\n",
    "def rmsle_np(y, y_hat):\n",
    "    y_hat = np.maximum(y_hat, 0)\n",
    "    return np.sqrt(np.mean((np.log1p(y_hat) - np.log1p(y)) ** 2))\n",
    "\n",
    "rmsle_scorer = make_scorer(rmsle_np, greater_is_better=False)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1.  CV splitter for the meta-learner\n",
    "#     (pass the *object* — not the generator — so the model is picklable)\n",
    "# -------------------------------------------------------------------\n",
    "bins = pd.qcut(y_meta, 4, labels=False)\n",
    "skf  = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2.  RidgeCV meta-model\n",
    "# -------------------------------------------------------------------\n",
    "alphas = np.logspace(-4, 3, 100)          # wide search range\n",
    "meta_model = RidgeCV(\n",
    "    alphas      = alphas,\n",
    "    scoring     = rmsle_scorer,\n",
    "    cv          = skf,                    # ← the fix: pass the splitter, not .split(...)\n",
    "    store_cv_values = False               # nothing extra to pickle\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3.  Train, evaluate, log to MLflow\n",
    "# -------------------------------------------------------------------\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"Calories-Stacked-Ridge\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"ridge_meta\"):\n",
    "    meta_model.fit(X_meta, y_meta)\n",
    "\n",
    "    # OOF evaluation (should be identical to training data here)\n",
    "    oof_pred   = meta_model.predict(X_meta)\n",
    "    oof_rmsle  = rmsle_np(y_meta, oof_pred)\n",
    "\n",
    "    mlflow.log_metric(\"oof_rmsle\", oof_rmsle)\n",
    "    mlflow.log_param(\"best_alpha\", float(meta_model.alpha_))\n",
    "\n",
    "    # persist the sklearn model (pure pickle, no TF dependency)\n",
    "    model_path = Path(\"meta_ridge.pkl\")\n",
    "    joblib.dump(meta_model, model_path)\n",
    "    mlflow.log_artifact(model_path, artifact_path=\"model\")\n",
    "\n",
    "print(f\"Saved stacked ridge ✅  –  OOF RMSLE: {oof_rmsle:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62b6c13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/31 17:38:10 INFO mlflow.tracking.fluent: Experiment with name 'Calories-Stacked-XGB+CB' does not exist. Creating a new experiment.\n",
      "C:\\Users\\afise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_ridge.py:2341: FutureWarning: 'store_cv_values' is deprecated in version 1.5 and will be removed in 1.7. Use 'store_cv_results' instead.\n",
      "  warnings.warn(\n",
      "2025/05/31 17:38:27 INFO mlflow.tracking._tracking_service.client: 🏃 View run ridge_meta_xgb_cb at: http://127.0.0.1:5000/#/experiments/32/runs/5a417207e81a4568b42161dbaee70ea1.\n",
      "2025/05/31 17:38:27 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/32.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked ridge (XGB+CB) logged ✅   OOF RMSLE: 0.060115\n"
     ]
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────────\n",
    "#  STACKING  ➜  meta-learner on top of XGB + CB   (no NN this time)\n",
    "# ────────────────────────────────────────────────────────────────────\n",
    "import numpy as np, pandas as pd, joblib, mlflow\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 0.  Prepare meta-features\n",
    "# -------------------------------------------------------------------\n",
    "# make sure oof_xgb and oof_cb are in memory\n",
    "assert oof_xgb.shape == oof_cb.shape, \"OOF vectors have different lengths\"\n",
    "\n",
    "X_meta = np.vstack([oof_xgb, oof_cb]).T          # (n_samples, 2)\n",
    "y_meta = y_true                                  # ground-truth targets\n",
    "\n",
    "def rmsle_np(y, y_hat):\n",
    "    y_hat = np.maximum(y_hat, 0)\n",
    "    return np.sqrt(np.mean((np.log1p(y_hat) - np.log1p(y)) ** 2))\n",
    "\n",
    "rmsle_scorer = make_scorer(rmsle_np, greater_is_better=False)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1.  Stratified K-fold for RidgeCV\n",
    "# -------------------------------------------------------------------\n",
    "bins = pd.qcut(y_meta, 4, labels=False)\n",
    "skf  = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2.  RidgeCV meta-model\n",
    "# -------------------------------------------------------------------\n",
    "alphas     = np.logspace(-4, 3, 100)      # wide α grid\n",
    "meta_model = RidgeCV(\n",
    "    alphas      = alphas,\n",
    "    scoring     = rmsle_scorer,\n",
    "    cv          = skf,                    # pass the splitter *object*\n",
    "    store_cv_values=False\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3.  Train, evaluate, log to MLflow\n",
    "# -------------------------------------------------------------------\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"Calories-Stacked-XGB+CB\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"ridge_meta_xgb_cb\"):\n",
    "    meta_model.fit(X_meta, y_meta)\n",
    "\n",
    "    oof_pred  = meta_model.predict(X_meta)\n",
    "    oof_rmsle = rmsle_np(y_meta, oof_pred)\n",
    "\n",
    "    mlflow.log_metric(\"oof_rmsle\", oof_rmsle)\n",
    "    mlflow.log_param(\"best_alpha\", float(meta_model.alpha_))\n",
    "    mlflow.log_param(\"features\",   \"XGB,CB\")\n",
    "\n",
    "    # save the sklearn ridge (pure pickle, no TF deps)\n",
    "    model_path = Path(\"meta_ridge_xgb_cb.pkl\")\n",
    "    joblib.dump(meta_model, model_path)\n",
    "    mlflow.log_artifact(model_path, artifact_path=\"model\")\n",
    "\n",
    "print(f\"Stacked ridge (XGB+CB) logged ✅   OOF RMSLE: {oof_rmsle:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2eacce9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/31 18:32:03 INFO mlflow.tracking.fluent: Experiment with name 'Calories-Stacked-XGB+NN' does not exist. Creating a new experiment.\n",
      "C:\\Users\\afise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_ridge.py:2341: FutureWarning: 'store_cv_values' is deprecated in version 1.5 and will be removed in 1.7. Use 'store_cv_results' instead.\n",
      "  warnings.warn(\n",
      "2025/05/31 18:32:20 INFO mlflow.tracking._tracking_service.client: 🏃 View run ridge_meta_xgb_nn at: http://127.0.0.1:5000/#/experiments/34/runs/f5b1c411b36148179f71aaa16677dc0f.\n",
      "2025/05/31 18:32:20 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/34.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked ridge (XGB+NN) logged ✅   OOF RMSLE: 0.059838\n",
      "MLflow run_id: f5b1c411b36148179f71aaa16677dc0f\n"
     ]
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────────\n",
    "#  STACKING  ➜  meta-learner on top of XGB + NN\n",
    "# ────────────────────────────────────────────────────────────────────\n",
    "import numpy as np, pandas as pd, joblib, mlflow\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 0.  Prepare meta-features\n",
    "# -------------------------------------------------------------------\n",
    "# make sure oof_xgb and oof_nn are already in memory, and y_true is the target\n",
    "assert oof_xgb.shape == oof_nn.shape, \"OOF vectors have different lengths\"\n",
    "\n",
    "X_meta = np.vstack([oof_xgb, oof_nn]).T        # (n_samples, 2)\n",
    "y_meta = y_true                                # ground-truth targets\n",
    "\n",
    "def rmsle_np(y, y_hat):\n",
    "    y_hat = np.maximum(y_hat, 0)\n",
    "    return np.sqrt(np.mean((np.log1p(y_hat) - np.log1p(y)) ** 2))\n",
    "\n",
    "rmsle_scorer = make_scorer(rmsle_np, greater_is_better=False)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1.  Stratified K-fold for RidgeCV\n",
    "# -------------------------------------------------------------------\n",
    "bins = pd.qcut(y_meta, 4, labels=False)\n",
    "skf  = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2.  RidgeCV meta-model\n",
    "# -------------------------------------------------------------------\n",
    "alphas     = np.logspace(-4, 3, 100)           # wide α grid\n",
    "meta_model = RidgeCV(\n",
    "    alphas      = alphas,\n",
    "    scoring     = rmsle_scorer,\n",
    "    cv          = skf,\n",
    "    store_cv_values=False\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3.  Train, evaluate, log to MLflow\n",
    "# -------------------------------------------------------------------\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"Calories-Stacked-XGB+NN\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"ridge_meta_xgb_nn\") as run:\n",
    "    meta_model.fit(X_meta, y_meta)\n",
    "\n",
    "    oof_pred  = meta_model.predict(X_meta)\n",
    "    oof_rmsle = rmsle_np(y_meta, oof_pred)\n",
    "\n",
    "    mlflow.log_metric(\"oof_rmsle\", oof_rmsle)\n",
    "    mlflow.log_param(\"best_alpha\", float(meta_model.alpha_))\n",
    "    mlflow.log_param(\"features\",   \"XGB,NN\")\n",
    "\n",
    "    # save the sklearn ridge model\n",
    "    model_path = Path(\"meta_ridge_xgb_nn.pkl\")\n",
    "    joblib.dump(meta_model, model_path)\n",
    "    mlflow.log_artifact(model_path, artifact_path=\"model\")\n",
    "\n",
    "print(f\"Stacked ridge (XGB+NN) logged ✅   OOF RMSLE: {oof_rmsle:.6f}\")\n",
    "print(\"MLflow run_id:\", run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c82edce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF RMSLE  XGB : 0.060336\n",
      "OOF RMSLE  CB  : 0.060766\n",
      "OOF RMSLE  NN  : 0.060649\n",
      "XGB vs CB : ΔSLE t=-4.51, p=6.43e-06\n",
      "XGB vs NN : ΔSLE t=-1.53, p=0.126\n",
      "CB vs NN : ΔSLE t=0.63, p=0.526\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# metrics & paired t-tests\n",
    "# ------------------------------------------------------------\n",
    "y_true = y.values          # ground truth used in OOF generation\n",
    "\n",
    "def rmsle_vec(y, y_hat):\n",
    "    return np.sqrt(np.mean((np.log1p(np.clip(y_hat, 0, None)) -\n",
    "                            np.log1p(y))**2))\n",
    "\n",
    "rmsle_xgb = rmsle_vec(y_true, oof_xgb)\n",
    "rmsle_cb  = rmsle_vec(y_true, oof_cb)\n",
    "rmsle_nn  = rmsle_vec(y_true, oof_nn)\n",
    "\n",
    "print(f\"OOF RMSLE  XGB : {rmsle_xgb:.6f}\")\n",
    "print(f\"OOF RMSLE  CB  : {rmsle_cb :.6f}\")\n",
    "print(f\"OOF RMSLE  NN  : {rmsle_nn :.6f}\")\n",
    "\n",
    "# per-row squared-log errors\n",
    "sle_xgb = (np.log1p(np.clip(oof_xgb, 0, None)) - np.log1p(y_true))**2\n",
    "sle_cb  = (np.log1p(np.clip(oof_cb , 0, None)) - np.log1p(y_true))**2\n",
    "sle_nn  = (np.log1p(np.clip(oof_nn , 0, None)) - np.log1p(y_true))**2\n",
    "\n",
    "def report_t(a, b, name_a, name_b):\n",
    "    t_stat, p_val = ttest_rel(a, b)\n",
    "    print(f\"{name_a} vs {name_b} : ΔSLE t={t_stat:.2f}, p={p_val:.3g}\")\n",
    "\n",
    "report_t(sle_xgb, sle_cb, \"XGB\", \"CB\")\n",
    "report_t(sle_xgb, sle_nn, \"XGB\", \"NN\")\n",
    "report_t(sle_cb , sle_nn, \"CB\" , \"NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01029016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal weight (XGB share) = 0.629\n",
      "Blended OOF RMSLE = 0.060107\n"
     ]
    }
   ],
   "source": [
    "def rmsle_blend(w):\n",
    "    blend = w * oof_xgb + (1 - w) * oof_cb\n",
    "    return rmsle_vec(y_true, blend)\n",
    "\n",
    "opt = minimize_scalar(rmsle_blend, bounds=(0, 1), method=\"bounded\")\n",
    "w_opt = opt.x\n",
    "print(f\"Optimal weight (XGB share) = {w_opt:.3f}\")\n",
    "print(f\"Blended OOF RMSLE = {opt.fun:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4e87461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal weights  →  XGB 0.399,  CB 0.174,  NN 0.426\n",
      "Blended OOF RMSLE = 0.059716\n"
     ]
    }
   ],
   "source": [
    "# three OOF vectors already in memory\n",
    "y_true  = y.values               # ground-truth targets\n",
    "oofs    = np.column_stack([oof_xgb, oof_cb, oof_nn])   # shape (n_rows, 3)\n",
    "\n",
    "def rmsle_from_weights(w12):                     # w12 = [w_xgb, w_cb]\n",
    "    w1, w2 = w12\n",
    "    if w1 < 0 or w2 < 0 or w1 + w2 > 1:          # keep inside simplex\n",
    "        return np.inf\n",
    "    w3      = 1.0 - w1 - w2                      # weight for NN\n",
    "    blend   = (oofs * [w1, w2, w3]).sum(axis=1)\n",
    "    return rmsle_vec(y_true, blend)\n",
    "\n",
    "# start at equal weights, constrain to [0,1] box-square\n",
    "result = minimize(\n",
    "    rmsle_from_weights,\n",
    "    x0=[1/3, 1/3],\n",
    "    bounds=[(0, 1), (0, 1)],\n",
    "    method=\"L-BFGS-B\"\n",
    ")\n",
    "\n",
    "w_xgb, w_cb = result.x\n",
    "w_nn        = 1.0 - w_xgb - w_cb\n",
    "\n",
    "print(f\"Optimal weights  →  XGB {w_xgb:.3f},  CB {w_cb:.3f},  NN {w_nn:.3f}\")\n",
    "print(f\"Blended OOF RMSLE = {result.fun:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e2619db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999213467873572\n",
      "0.99977438333897\n",
      "0.9998097861747608\n"
     ]
    }
   ],
   "source": [
    "print(np.corrcoef(oof_xgb, oof_cb)[0,1])   # ~0.93  (very similar)\n",
    "print(np.corrcoef(oof_xgb, oof_nn)[0,1])   # ~0.88\n",
    "print(np.corrcoef(oof_cb , oof_nn)[0,1])   # ~0.87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e0cfe2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/31 13:05:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/31 13:05:50 INFO mlflow.tracking._tracking_service.client: 🏃 View run catboost_final_fit_v2 at: http://127.0.0.1:5000/#/experiments/28/runs/4a9b55aebbce4b4f9d87ecd98a596d45.\n",
      "2025/05/31 13:05:50 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/28.\n"
     ]
    }
   ],
   "source": [
    "# FINAL-MODEL RUN  ──────────────────────────────────────────────\n",
    "best_params = {\n",
    "    \"model__depth\":               10,\n",
    "    \"model__iterations\":          1594,\n",
    "    \"model__learning_rate\":       0.08318728723922084,\n",
    "    \"model__l2_leaf_reg\":         3.7912206788501206,\n",
    "    \"model__bagging_temperature\": 0.3000645110427449,\n",
    "}\n",
    "\n",
    "cat_final = CatBoostRegressor(\n",
    "        loss_function=\"RMSE\",\n",
    "        random_seed=42,\n",
    "        verbose=False,\n",
    "        cat_features=[\"Sex\"]\n",
    ")\n",
    "\n",
    "final_pipe = Pipeline([\n",
    "        (\"feat_eng\", feat_eng),\n",
    "        (\"model\",    cat_final)\n",
    "]).set_params(**best_params)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Fit on the full dataset (train + val)\n",
    "# ------------------------------------------------------------------\n",
    "X_full = pd.concat([X_train, X_val])\n",
    "y_full = pd.concat([y_train, y_val])\n",
    "\n",
    "final_pipe.fit(X_full, y_full)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Save / log the artefact\n",
    "# ------------------------------------------------------------------\n",
    "joblib.dump(final_pipe, \"calories_catboost_optuna.joblib\")\n",
    "\n",
    "# Log to MLflow\n",
    "with mlflow.start_run(run_name=\"catboost_final_fit_v2\"):\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.sklearn.log_model(final_pipe, artifact_path=\"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
