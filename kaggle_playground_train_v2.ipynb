{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe49eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\\nmlflow.set_experiment(\"Calories-XGB-Optuna-V3\")\\nmlflow.sklearn.autolog(log_models=False)\\n\\nstudy = optuna.create_study(direction=\"maximize\", study_name=\"xgb_rmsle_1\")\\n\\nwith mlflow.start_run(run_name=\"optuna_parent\"):\\n    mlflow_cb = MLflowCallback(\\n        tracking_uri=mlflow.get_tracking_uri(),\\n        metric_name=\"neg_rmsle_cv\",\\n        mlflow_kwargs={\"nested\": True}\\n    )\\n\\n    study.optimize(\\n        objective,\\n        n_trials=150,\\n        callbacks=[mlflow_cb],\\n        show_progress_bar=True\\n    )\\n\\n    mlflow.log_params(study.best_trial.params)\\n    mlflow.log_metric(\"best_neg_rmsle_cv\", study.best_value)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.compose         import ColumnTransformer\n",
    "from sklearn.preprocessing   import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics         import make_scorer\n",
    "from sklearn.base            import clone\n",
    "from xgboost                 import XGBRegressor\n",
    "import joblib, mlflow\n",
    "import mlflow.sklearn\n",
    "import optuna\n",
    "import warnings\n",
    "from optuna.integration import OptunaSearchCV, MLflowCallback\n",
    "from optuna.distributions import FloatDistribution, IntDistribution\n",
    "\n",
    "# Custom Metric for Training Feedback\n",
    "def rmsle_xgb(preds, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    preds = np.maximum(preds, 0)\n",
    "    rmsle = np.sqrt(np.mean((np.log1p(preds) - np.log1p(y_true)) ** 2))\n",
    "    return 'rmsle', rmsle\n",
    "\n",
    "# Custom Metric for GridSearch (wrapped in make_scorer)\n",
    "def rmsle_sklearn(y_true, y_pred):\n",
    "    y_pred = np.maximum(y_pred, 0)\n",
    "    return np.sqrt(np.mean((np.log1p(y_pred) - np.log1p(y_true)) ** 2))\n",
    "\n",
    "rmsle_scorer = make_scorer(rmsle_sklearn, greater_is_better=False)\n",
    "# Data\n",
    "df = pd.read_csv('playground-series-s5e5/train.csv')\n",
    "y = df['Calories']\n",
    "X = df.drop(columns=(['Calories', 'id']))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=X['Sex']\n",
    ")\n",
    "\n",
    "# Custom Feature Engineering\n",
    "def add_bmi_intensity(X_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Adds BMI and HeartRatexDuration features\"\"\"\n",
    "    X = X_df.copy()\n",
    "    X['BMI'] = (X['Weight'] / (X['Height'] / 100) ** 2).round(2)\n",
    "    X['Timed_Intensity'] = X['Duration'] * X['Heart_Rate']\n",
    "    X['Heart_Rate_Zone'] = (\n",
    "        X['Heart_Rate'] / (220 - X['Age'])\n",
    "    ) * 100\n",
    "    X['Mifflin_Jeor_BMR'] = np.where(\n",
    "        X['Sex'] == 'male',\n",
    "        (10 * X['Weight']) + (6.25 * X['Height']) - (5 * X['Age']) + 5,\n",
    "        (10 * X['Weight']) + (6.25 * X['Height']) - (5 * X['Age']) - 161,\n",
    "    )\n",
    "    return X\n",
    "\n",
    "feat_eng = FunctionTransformer(add_bmi_intensity, validate=False)\n",
    "\n",
    "# Preprocessor\n",
    "cat_col = ['Sex']\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first'), cat_col)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# MODEL & PIPELINE\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "xgb = XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=42,\n",
    "        n_estimators=800,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "        (\"feat_eng\",   feat_eng),\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"model\",      xgb)\n",
    "])\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# GRID  (prefix params with model__)\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    params = {\n",
    "        \"model__max_depth\":        trial.suggest_int(\"model__max_depth\", 3, 10),\n",
    "        \"model__learning_rate\":    trial.suggest_float(\"model__learning_rate\", 1e-3, 0.2, log=True),\n",
    "        \"model__n_estimators\":     trial.suggest_int(\"model__n_estimators\", 400, 1600),\n",
    "        \"model__subsample\":        trial.suggest_float(\"model__subsample\", 0.6, 1.0),\n",
    "        \"model__colsample_bytree\": trial.suggest_float(\"model__colsample_bytree\", 0.6, 1.0),\n",
    "        \"model__reg_alpha\":        trial.suggest_float(\"model__reg_alpha\", 1e-4, 10.0, log=True),\n",
    "        \"model__reg_lambda\":       trial.suggest_float(\"model__reg_lambda\", 1e-3, 10.0, log=True),\n",
    "        \"model__min_child_weight\": trial.suggest_float(\"model__min_child_weight\", 1e-2, 10.0, log=True),\n",
    "    }\n",
    "\n",
    "    pipe_trial = clone(pipe).set_params(**params)\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        pipe_trial,\n",
    "        X_train, y_train,\n",
    "        scoring=rmsle_scorer,\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    return scores.mean()\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# MLFLOW SETUP\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "'''\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"Calories-XGB-Optuna-V3\")\n",
    "mlflow.sklearn.autolog(log_models=False)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"xgb_rmsle_1\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"optuna_parent\"):\n",
    "    mlflow_cb = MLflowCallback(\n",
    "        tracking_uri=mlflow.get_tracking_uri(),\n",
    "        metric_name=\"neg_rmsle_cv\",\n",
    "        mlflow_kwargs={\"nested\": True}\n",
    "    )\n",
    "\n",
    "    study.optimize(\n",
    "        objective,\n",
    "        n_trials=150,\n",
    "        callbacks=[mlflow_cb],\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    mlflow.log_params(study.best_trial.params)\n",
    "    mlflow.log_metric(\"best_neg_rmsle_cv\", study.best_value)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36357cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>rmsle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.060138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.060464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.059776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.061001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.060293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold     rmsle\n",
       "0     1  0.060138\n",
       "1     2  0.060464\n",
       "2     3  0.059776\n",
       "3     4  0.061001\n",
       "4     5  0.060293"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/26 00:34:07 INFO mlflow.tracking._tracking_service.client: 🏃 View run xgb_oof_fit at: http://127.0.0.1:5000/#/experiments/15/runs/218fddecf5604ade89ce336140857574.\n",
      "2025/05/26 00:34:07 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/15.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold CV RMLSE: 0.06033\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────\n",
    "# GENERATING OOF PREDICTIONS AND A VAL SCORE\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "FE_VERSION = 'v4_hrzone_bmr'\n",
    "\n",
    "best_params = {\n",
    "    \"model__max_depth\": 10,\n",
    "    \"model__learning_rate\": 0.02350055429195408,\n",
    "    \"model__n_estimators\": 1236,\n",
    "    \"model__subsample\": 0.9920046553420347,\n",
    "    \"model__colsample_bytree\": 0.7191809335449328,\n",
    "    \"model__reg_alpha\": 4.560438869008341,\n",
    "    \"model__reg_lambda\": 3.5346229827585867,\n",
    "    \"model__min_child_weight\": 0.08981320070110384 \n",
    "}\n",
    "\n",
    "best_pipe = clone(pipe).set_params(**best_params)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_table = []\n",
    "oof_xgb = np.empty(len(X))\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"Calories-XGB-OOF-VAL-V2\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"xgb_oof_fit\",\n",
    "                      tags={\"fe_version\": FE_VERSION}):\n",
    "    \n",
    "    for fold, (tr_idx, val_idx) in enumerate(tqdm(kf.split(X, y), total=kf.get_n_splits()), 1):\n",
    "        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "\n",
    "        fold_model = clone(best_pipe).fit(X_tr, y_tr)\n",
    "        preds = fold_model.predict(X_val)\n",
    "\n",
    "        oof_xgb[val_idx] = preds\n",
    "\n",
    "        fold_rmsle = rmsle_sklearn(y_val, preds)\n",
    "        mlflow.log_metric(f\"fold{fold}_rmsle\", fold_rmsle)\n",
    "\n",
    "        fold_table.append({\"fold\": fold, \"rmsle\": fold_rmsle})\n",
    "        clear_output(wait=True)\n",
    "        display(pd.DataFrame(fold_table))\n",
    "\n",
    "    cv_rmsle = np.mean([row[\"rmsle\"] for row in fold_table])\n",
    "    mlflow.log_metric(\"cv_rmsle\", cv_rmsle)\n",
    "    print(f\"5-fold CV RMSLE: {cv_rmsle:.5f}\")\n",
    "\n",
    "    Path(\"oof\").mkdir(exist_ok=True)\n",
    "    np.save(\"oof/oof_xgb.npy\", oof_xgb)\n",
    "    mlflow.log_artifact(\"oof/oof_xgb.npy\", artifact_path=\"oof\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7647d83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/24 15:15:57 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\Users\\afise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2025/05/24 15:16:30 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"C:\\Users\\afise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\compose\\_column_transformer.py:1623: FutureWarning: \n",
      "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\"\n",
      "2025/05/24 15:16:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/24 15:16:44 INFO mlflow.tracking._tracking_service.client: 🏃 View run final_rmsle_model_optuna at: http://127.0.0.1:5000/#/experiments/8/runs/bfdc77e266614b8d9d642cc56e14816b.\n",
      "2025/05/24 15:16:44 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/8.\n"
     ]
    }
   ],
   "source": [
    "# FINAL-MODEL RUN  ──────────────────────────────────────────────\n",
    "with mlflow.start_run(run_name=\"final_rmsle_model_optuna\") as run:\n",
    "\n",
    "    best_params = {\n",
    "    \"model__max_depth\": 10,\n",
    "    \"model__learning_rate\": 0.02350055429195408,\n",
    "    \"model__n_estimators\": 1236,\n",
    "    \"model__subsample\": 0.9920046553420347,\n",
    "    \"model__colsample_bytree\": 0.7191809335449328,\n",
    "    \"model__reg_alpha\": 4.560438869008341,\n",
    "    \"model__reg_lambda\": 3.5346229827585867,\n",
    "    \"model__min_child_weight\": 0.08981320070110384\n",
    "    }\n",
    "\n",
    "    # fresh clone to avoid any state leakage from grid-search\n",
    "    best_pipe = clone(pipe).set_params(\n",
    "            **best_params\n",
    "    )\n",
    "\n",
    "    # concatenating to train on the full dataset\n",
    "    X_full = pd.concat([X_train, X_val])\n",
    "    y_full = pd.concat([y_train, y_val])\n",
    "    \n",
    "    best_pipe.fit(X_full, y_full)\n",
    "\n",
    "    mlflow.sklearn.log_model(best_pipe, artifact_path=\"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
