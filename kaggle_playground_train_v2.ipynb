{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebe49eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.compose         import ColumnTransformer\n",
    "from sklearn.preprocessing   import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics         import make_scorer\n",
    "from sklearn.base            import clone\n",
    "from xgboost                 import XGBRegressor\n",
    "import mlflow\n",
    "import optuna\n",
    "from optuna.integration import MLflowCallback\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Custom Metric for Training Feedback\n",
    "def rmsle_xgb(preds, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    preds = np.maximum(preds, 0)\n",
    "    rmsle = np.sqrt(np.mean((np.log1p(preds) - np.log1p(y_true)) ** 2))\n",
    "    return 'rmsle', rmsle\n",
    "\n",
    "# Custom Metric for GridSearch (wrapped in make_scorer)\n",
    "def rmsle_sklearn(y_true, y_pred):\n",
    "    y_pred = np.maximum(y_pred, 0)\n",
    "    return np.sqrt(np.mean((np.log1p(y_pred) - np.log1p(y_true)) ** 2))\n",
    "\n",
    "rmsle_scorer = make_scorer(rmsle_sklearn, greater_is_better=False)\n",
    "\n",
    "# Data\n",
    "df = pd.read_csv('playground-series-s5e5/train.csv')\n",
    "y = df['Calories']\n",
    "X = df.drop(columns=(['Calories', 'id']))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=X['Sex']\n",
    ")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1.  Feature-engineering helpers\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def add_bmi_intensity(X_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Adds BMI, Timed_Intensity, Heart-Rate zone and BMR features.\"\"\"\n",
    "    X = X_df.copy()\n",
    "    X['BMI']              = (X['Weight'] / (X['Height']/100)**2).round(2)\n",
    "    X['Timed_Intensity']  = X['Duration'] * X['Heart_Rate']\n",
    "    X['Heart_Rate_Zone']  = 100 * X['Heart_Rate'] / (220 - X['Age'])\n",
    "    X['Mifflin_Jeor_BMR'] = np.where(\n",
    "        X['Sex'] == 'male',\n",
    "        10*X['Weight'] + 6.25*X['Height'] - 5*X['Age'] + 5,\n",
    "       10*X['Weight'] + 6.25*X['Height'] - 5*X['Age'] - 161,\n",
    "    )\n",
    "    return X\n",
    "\n",
    "\n",
    "def add_sex_interactions(\n",
    "        X_df: pd.DataFrame,\n",
    "        features=('Duration', 'Heart_Rate', 'Body_Temp'),\n",
    "        gender_col='Sex'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds (feature Ã— Sex) interaction columns.\n",
    "    Creates two new columns per feature:\n",
    "        <feature>_x_Male, <feature>_x_Female\n",
    "    \"\"\"\n",
    "    X = X_df.copy()\n",
    "\n",
    "    # Turn the text label into a {0,1} indicator\n",
    "    male    = (X[gender_col] == 'male').astype(int)\n",
    "    female  = 1 - male\n",
    "\n",
    "    for feat in features:\n",
    "        X[f'{feat}_x_Male']   = X[feat] * male\n",
    "        X[f'{feat}_x_Female'] = X[feat] * female\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "# Wrap them so scikit-learn can call them\n",
    "feat_eng      = FunctionTransformer(add_bmi_intensity,            validate=False)\n",
    "interaction_eng = FunctionTransformer(\n",
    "    add_sex_interactions,\n",
    "    validate=False,\n",
    "    kw_args={'features': ['Duration', 'Heart_Rate', 'Body_Temp']}\n",
    ")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2.  Pre-processor (same as before)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cat_col = ['Sex']\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first'), cat_col)  # adds a single \"Sex_male\" column\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3.  Model\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "xgb = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    "    n_estimators=800,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8\n",
    ")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 4.  Pipeline\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"feat_eng\",        feat_eng),          # BMI, BMR, etc.\n",
    "    (\"interaction_eng\", interaction_eng),   # Sex-interactions\n",
    "    (\"preprocess\",      preprocess),        # One-Hot encode Sex\n",
    "    (\"model\",           xgb)\n",
    "])\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 5.  Optuna objective remains unchanged\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    params = {\n",
    "        \"model__max_depth\":        trial.suggest_int(\"model__max_depth\", 3, 10),\n",
    "        \"model__learning_rate\":    trial.suggest_float(\"model__learning_rate\", 1e-3, 0.2, log=True),\n",
    "        \"model__n_estimators\":     trial.suggest_int(\"model__n_estimators\", 400, 1600),\n",
    "        \"model__subsample\":        trial.suggest_float(\"model__subsample\", 0.6, 1.0),\n",
    "        \"model__colsample_bytree\": trial.suggest_float(\"model__colsample_bytree\", 0.6, 1.0),\n",
    "        \"model__reg_alpha\":        trial.suggest_float(\"model__reg_alpha\", 1e-4, 10.0, log=True),\n",
    "        \"model__reg_lambda\":       trial.suggest_float(\"model__reg_lambda\", 1e-3, 10.0, log=True),\n",
    "        \"model__min_child_weight\": trial.suggest_float(\"model__min_child_weight\", 1e-2, 10.0, log=True),\n",
    "    }\n",
    "\n",
    "    pipe_trial = clone(pipe).set_params(**params)\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        pipe_trial,\n",
    "        X_train, y_train,\n",
    "        scoring=rmsle_scorer,\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e95be81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MLFLOW SETUP\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"Calories-XGB-Optuna-V3\")\n",
    "mlflow.sklearn.autolog(log_models=False)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"xgb_rmsle_1\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"optuna_parent\"):\n",
    "    mlflow_cb = MLflowCallback(\n",
    "        tracking_uri=mlflow.get_tracking_uri(),\n",
    "        metric_name=\"neg_rmsle_cv\",\n",
    "        mlflow_kwargs={\"nested\": True}\n",
    "    )\n",
    "\n",
    "    study.optimize(\n",
    "        objective,\n",
    "        n_trials=150,\n",
    "        callbacks=[mlflow_cb],\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    mlflow.log_params(study.best_trial.params)\n",
    "    mlflow.log_metric(\"best_neg_rmsle_cv\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d36357cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>rmsle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.060059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.060513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.059826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.061023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.060335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold     rmsle\n",
       "0     1  0.060059\n",
       "1     2  0.060513\n",
       "2     3  0.059826\n",
       "3     4  0.061023\n",
       "4     5  0.060335"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/31 18:20:32 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run xgb_oof_fit at: http://127.0.0.1:5000/#/experiments/33/runs/8022113a459c49289430e3a0a78ddab4.\n",
      "2025/05/31 18:20:32 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/33.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold CV RMSLE: 0.06035\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# GENERATING OOF PREDICTIONS AND A VAL SCORE\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "FE_VERSION = 'v4_hrzone_bmr_2'\n",
    "\n",
    "best_params = {\n",
    "    \"model__max_depth\": 10,\n",
    "    \"model__learning_rate\": 0.02350055429195408,\n",
    "    \"model__n_estimators\": 1236,\n",
    "    \"model__subsample\": 0.9920046553420347,\n",
    "    \"model__colsample_bytree\": 0.7191809335449328,\n",
    "    \"model__reg_alpha\": 4.560438869008341,\n",
    "    \"model__reg_lambda\": 3.5346229827585867,\n",
    "    \"model__min_child_weight\": 0.08981320070110384 \n",
    "}\n",
    "\n",
    "best_pipe = clone(pipe).set_params(**best_params)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_table = []\n",
    "oof_xgb = np.empty(len(X))\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"Calories-XGB-OOF-FINAL-GOLDEN\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"xgb_oof_fit\",\n",
    "                      tags={\"fe_version\": FE_VERSION}):\n",
    "    \n",
    "    for fold, (tr_idx, val_idx) in enumerate(tqdm(kf.split(X, y), total=kf.get_n_splits()), 1):\n",
    "        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "\n",
    "        fold_model = clone(best_pipe).fit(X_tr, y_tr)\n",
    "        preds = fold_model.predict(X_val)\n",
    "\n",
    "        oof_xgb[val_idx] = preds\n",
    "\n",
    "        fold_rmsle = rmsle_sklearn(y_val, preds)\n",
    "        mlflow.log_metric(f\"fold{fold}_rmsle\", fold_rmsle)\n",
    "\n",
    "        fold_table.append({\"fold\": fold, \"rmsle\": fold_rmsle})\n",
    "        clear_output(wait=True)\n",
    "        display(pd.DataFrame(fold_table))\n",
    "\n",
    "    cv_rmsle = np.mean([row[\"rmsle\"] for row in fold_table])\n",
    "    mlflow.log_metric(\"cv_rmsle\", cv_rmsle)\n",
    "    print(f\"5-fold CV RMSLE: {cv_rmsle:.5f}\")\n",
    "\n",
    "    Path(\"oof\").mkdir(exist_ok=True)\n",
    "    np.save(\"oof/oof_xgb.npy\", oof_xgb)\n",
    "    mlflow.log_artifact(\"oof/oof_xgb.npy\", artifact_path=\"oof\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7647d83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/31 18:23:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/31 18:23:43 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run final_rmsle_model_optuna_v4 at: http://127.0.0.1:5000/#/experiments/33/runs/d5175c90bf844565ac5343aba7984ff4.\n",
      "2025/05/31 18:23:43 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/33.\n"
     ]
    }
   ],
   "source": [
    "# FINAL-MODEL RUN  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "with mlflow.start_run(run_name=\"final_rmsle_model_optuna_v4\") as run:\n",
    "\n",
    "    best_params = {\n",
    "    \"model__max_depth\": 10,\n",
    "    \"model__learning_rate\": 0.02350055429195408,\n",
    "    \"model__n_estimators\": 1236,\n",
    "    \"model__subsample\": 0.9920046553420347,\n",
    "    \"model__colsample_bytree\": 0.7191809335449328,\n",
    "    \"model__reg_alpha\": 4.560438869008341,\n",
    "    \"model__reg_lambda\": 3.5346229827585867,\n",
    "    \"model__min_child_weight\": 0.08981320070110384\n",
    "    }\n",
    "\n",
    "    # fresh clone to avoid any state leakage from grid-search\n",
    "    best_pipe = clone(pipe).set_params(\n",
    "            **best_params\n",
    "    )\n",
    "\n",
    "    # concatenating to train on the full dataset\n",
    "    X_full = pd.concat([X_train, X_val])\n",
    "    y_full = pd.concat([y_train, y_val])\n",
    "    \n",
    "    best_pipe.fit(X_full, y_full)\n",
    "\n",
    "    mlflow.sklearn.log_model(best_pipe, artifact_path=\"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
